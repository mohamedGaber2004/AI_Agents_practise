{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21a6f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph.message import add_messages\n",
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage,HumanMessage , AnyMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph , START , END\n",
    "\n",
    "from langchain_community.tools import ArxivQueryRun , WikipediaQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper , WikipediaAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "from langgraph.prebuilt import ToolNode , tools_condition\n",
    "from IPython.display import Image , display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0a1db64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fcd80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e1c1ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2021-05-06\\nTitle: Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet\\nAuthors: Luke Melas-Kyriazi\\nSummary: The strong performance of vision transformers on image classification and other vision tasks is often attributed to the design of their multi-head attention layers. However, the extent to which attention is responsible for this strong performance remains unclear. In this short report, we ask: is the attention layer even necessary? Specifi'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.invoke(\"Attention is all you need\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc336eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wrapper = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=500)\n",
    "wiki = WikipediaQueryRun(api_wrapper=wiki_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b20f5863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Attention Is All You Need\\nSummary: \"Attention Is All You Need\" is a 2017 landmark research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al. It is considered a foundational paper in modern artificial intelligence, and a main contributor to the AI boom, as the transformer approach has become the main architecture of a wi'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.invoke(\"Attention is all you need\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e694c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mg735\\AppData\\Local\\Temp\\ipykernel_13944\\2290291758.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
      "  tavily = TavilySearchResults()\n"
     ]
    }
   ],
   "source": [
    "tavily = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1fd096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Attention Is All You Need - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/Attention_Is_All_You_Need',\n",
       "  'content': '\"Attention Is All You Need\" is a 2017 landmark research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer \"Transformer (machine learning model)\"), based on the attention mechanism proposed in 2014 by Bahdanau et al. It is considered a foundational paper in modern artificial intelligence, and a main contributor to the AI boom, as the transformer approach has become the main architecture of a [...] 1. ^ a b c d e f Vaswani, Ashish; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob; Jones, Llion; Gomez, Aidan N; Kaiser, Łukasz; Polosukhin, Illia (December 2017). \"Attention is All you Need\" (PDF). In I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett (ed.). 31st Conference on Neural Information Processing Systems (NIPS). Advances in Neural Information Processing Systems. Vol. 30. Curran Associates, Inc. arXiv \"ArXiv [...] In 2017, the original (100M-sized) encoder–decoder transformer model was proposed in the \"Attention is all you need\" paper. At the time, the focus of the research was on improving seq2seq for machine translation, by removing its recurrence to process all tokens in parallel, but preserving its dot-product attention mechanism to keep its text processing performance. This led to the introduction of a multi-head attention model that was easier to parallelize due to the use of independent heads and',\n",
       "  'score': 0.91175514},\n",
       " {'title': '[1706.03762] Attention Is All You Need - arXiv',\n",
       "  'url': 'https://arxiv.org/abs/1706.03762',\n",
       "  'content': 'We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\n\\n> cs > arXiv:1706.03762\\n\\n# Computer Science > Computation and Language\\n\\narXiv:1706.03762 (cs)\\n\\nSubmitted on 12 Jun 2017 ([v1), last revised 2 Aug 2023 (this version, v7)]\\n\\n# Title:Attention Is All You Need\\n\\nAuthors:Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin [...] From: Llion Jones [view email]   \\n (/abs/1706.03762v1) Mon, 12 Jun 2017 17:57:34 UTC (1,102 KB)  \\n (/abs/1706.03762v2) Mon, 19 Jun 2017 16:49:45 UTC (1,125 KB)  \\n (/abs/1706.03762v3) Tue, 20 Jun 2017 05:20:02 UTC (1,125 KB)  \\n (/abs/1706.03762v4) Fri, 30 Jun 2017 17:29:30 UTC (1,124 KB)  \\n (/abs/1706.03762v5) Wed, 6 Dec 2017 03:30:32 UTC (1,124 KB)  \\n (/abs/1706.03762v6) Mon, 24 Jul 2023 00:48:54 UTC (1,124 KB)  \\n [v7] Wed, 2 Aug 2023 00:41:18 UTC (1,124 KB)\\n\\nFull-text links:\\n\\n## Access Paper: [...] |  |  |\\n --- |\\n| Comments: | 15 pages, 5 figures |\\n| Subjects: | Computation and Language (cs.CL); Machine Learning (cs.LG) |\\n| Cite as: | arXiv:1706.03762 [cs.CL] |\\n|  | (or  arXiv:1706.03762v7 [cs.CL] for this version) |\\n|  |  arXiv-issued DOI via DataCite |\\n\\n## Submission history',\n",
       "  'score': 0.7634314},\n",
       " {'title': '[PDF] Attention is All you Need - NIPS papers',\n",
       "  'url': 'https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf',\n",
       "  'content': 'Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. Self-attention has been used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations [4, 22, 23, 19]. [...] 3.2 Attention An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key. [...] In this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.',\n",
       "  'score': 0.75659186},\n",
       " {'title': '11. Attention Mechanisms and Transformers - Dive into Deep Learning',\n",
       "  'url': 'http://www.d2l.ai/chapter_attention-mechanisms-and-transformers/index.html',\n",
       "  'content': 'However, attention mechanisms soon emerged as more significant concerns, beyond their usefulness as an enhancement for encoder–decoder recurrent neural networks and their putative usefulness for picking out salient inputs. Vaswani et al. (2017. Attention is all you need. Advances in Neural Information Processing Systems (pp. 5998–6008).\")) proposed the Transformer architecture for machine translation, dispensing with recurrent connections altogether, and instead relying on cleverly arranged',\n",
       "  'score': 0.70336664},\n",
       " {'title': 'Attention is all you need | Proceedings of the 31st International ...',\n",
       "  'url': 'https://dl.acm.org/doi/10.5555/3295222.3295349',\n",
       "  'content': 'skip to main content\\n\\nAdvanced Search\\n\\n10.5555/3295222.3295349guideproceedingsArticle/Chapter ViewAbstractPublication PagesnipsConference Proceedingsconference-collections\\n\\nnips\\n\\n## Export Citations\\n\\nFree access\\n\\nShare on\\n\\n# Attention is all you need\\n\\nAuthors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, + 4, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin (Less)Authors Info & Claims [...] Google Scholar\\n\\nMinh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-based neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n\\nGoogle Scholar\\n\\nAnkur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention model. In Empirical Methods in Natural Language Processing, 2016.\\n\\nGoogle Scholar [...] Google Scholar\\n\\nSainbayar Sukhbaatar, arthur szlam, Jason Weston, and Rob Fergus. End-to-end memory networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2440-2448. Curran Associates, Inc., 2015.\\n\\nDigital Library\\n\\nGoogle Scholar',\n",
       "  'score': 0.69795954}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily.invoke(\"Attention is all you need\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "875d3e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [arxiv,wiki,tavily]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5ce20b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model = \"openai/gpt-oss-120b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f64c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm_with_tools.invoke([HumanMessage(content=\"What is recent ai news ?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4597fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'AI news December 2025'},\n",
       "  'id': 'fc_b86433e9-0857-44fd-b2d0-9e0803ff3f60',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b9ce389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'The user asks: \"What is recent ai news ?\" They want recent AI news. Need to provide up-to-date information. As of current date 2025-12-13. Need to browse recent AI news. Use search tool. Probably use tavily_search_results_json for news. Let\\'s search query \"latest AI news December 2025\".', 'tool_calls': [{'id': 'fc_b86433e9-0857-44fd-b2d0-9e0803ff3f60', 'function': {'arguments': '{\"query\":\"AI news December 2025\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 107, 'prompt_tokens': 291, 'total_tokens': 398, 'completion_time': 0.264928892, 'completion_tokens_details': {'reasoning_tokens': 71}, 'prompt_time': 0.027912864, 'prompt_tokens_details': None, 'queue_time': 0.037202388, 'total_time': 0.292841756}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_1e478dac32', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--5370cfe2-4f96-4864-99dc-d06fd1a59b4f-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'AI news December 2025'}, 'id': 'fc_b86433e9-0857-44fd-b2d0-9e0803ff3f60', 'type': 'tool_call'}], usage_metadata={'input_tokens': 291, 'output_tokens': 107, 'total_tokens': 398, 'output_token_details': {'reasoning': 71}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ebef180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State (TypedDict) : \n",
    "    messages : Annotated[list[AnyMessage],add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afaa51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_node (state:State) : \n",
    "    return {\"messages\" : [llm_with_tools.invoke(state['messages'])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed592db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"llm_node\", llm_node)\n",
    "graph.add_node(\"tools\", ToolNode(tools_list))\n",
    "\n",
    "graph.add_edge(START, \"llm_node\")\n",
    "graph.add_conditional_edges(\n",
    "    \"llm_node\",\n",
    "    tools_condition,   # function\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"END\": END\n",
    "    }\n",
    ")\n",
    "graph.add_edge(\"tools\", END)\n",
    "\n",
    "graph = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f20c46af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "009b15df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "1706.03762\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (fc_26930eaf-f15a-47fa-9920-900e12e1562d)\n",
      " Call ID: fc_26930eaf-f15a-47fa-9920-900e12e1562d\n",
      "  Args:\n",
      "    query: 1706.03762\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv\n",
      "\n",
      "Published: 2023-08-02\n",
      "Title: Attention Is All You Need\n",
      "Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
      "Summary: The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, base\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\" : HumanMessage(content=\"1706.03762\")})\n",
    "for m in messages['messages'] : \n",
    "    pprint(m.pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2c7903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
