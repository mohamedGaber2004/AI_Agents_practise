{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef9818a",
   "metadata": {},
   "source": [
    "# Real World Application \n",
    "- Customer Service bots (simple queries -> Qwen3 , complex issues -> GPT-OSS)\n",
    "- Research assistants (quick facts -> Qwen3 , analysis -> GPT-OSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "81fbd17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent , AgentState\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain.tools import tool\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e802bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "math = PythonREPLTool()\n",
    "web_search = DuckDuckGoSearchRun()\n",
    "\n",
    "@tool\n",
    "def analyze_data(data: list, operation: str = \"df.describe()\") -> str:\n",
    "    \"\"\"\n",
    "    Dynamic pandas data analysis tool.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "    except ImportError as e:\n",
    "        return f\"Missing dependency: {e}\"\n",
    "\n",
    "    if not data or not isinstance(data, list):\n",
    "        return \"Data must be a non-empty list.\"\n",
    "\n",
    "    try:\n",
    "        df = pd.DataFrame(data)\n",
    "    except Exception as e:\n",
    "        return f\"Failed to create DataFrame: {str(e)}\"\n",
    "\n",
    "    if df.empty:\n",
    "        return \"Empty DataFrame created.\"\n",
    "\n",
    "    namespace = {\"df\": df, \"pd\": pd, \"np\": np}\n",
    "    try:\n",
    "        result = eval(operation, {\"__builtins__\": {}}, namespace)\n",
    "    except SyntaxError:\n",
    "        return \"Invalid operation syntax.\"\n",
    "    except Exception as e:\n",
    "        return f\"Operation error: {str(e)}\"\n",
    "\n",
    "    if isinstance(result, (pd.DataFrame, pd.Series)):\n",
    "        return result.to_string()\n",
    "    else:\n",
    "        return str(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2a3a09",
   "metadata": {},
   "source": [
    "## Model Selection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "357ffdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm1 = ChatOllama(\n",
    "    model=\"qwen3:4b\",\n",
    "    temperature=0.1\n",
    ")\n",
    "llm2 = ChatOllama(\n",
    "    model=\"qwen3:4b\",\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1402056d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model selection function ready!\n"
     ]
    }
   ],
   "source": [
    "tools_list = [analyze_data, web_search, math]\n",
    "\n",
    "@wrap_model_call\n",
    "def select_model(request: ModelRequest, handler) -> ModelResponse:\n",
    "    \"\"\"Choose model based on conversation complexity.\"\"\"\n",
    "    \n",
    "    message_count = len(request.state[\"messages\"])\n",
    "\n",
    "    if message_count < 10:\n",
    "        print(f\"[Agent] Using qwen3:4b for {message_count} messages (efficient)\")\n",
    "        llm = llm1\n",
    "    else:\n",
    "        print(f\"[Agent] Using qwen3:4b for {message_count} messages (advanced)\")\n",
    "        llm = llm2\n",
    "\n",
    "    request.model = llm\n",
    "    return handler(request)\n",
    "\n",
    "print(\"✅ Model selection function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9318e6d9",
   "metadata": {},
   "source": [
    "## Create Dynamic Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bc465bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=llm1,  # Default model\n",
    "    tools=tools_list,\n",
    "    middleware=[select_model]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b0064",
   "metadata": {},
   "source": [
    "### Test 1 - Short Conversaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "85ff4745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] Using qwen3:4b for 1 messages (efficient)\n",
      "[Agent] Using qwen3:4b for 3 messages (efficient)\n"
     ]
    }
   ],
   "source": [
    "res_1 = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Search for me about latest Ai News\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "adf41377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are the latest AI news highlights based on recent reports:\n",
      "\n",
      "- **Reuters** covers AI breakthroughs, technology trends, regulatory developments, ethical concerns, business impacts, and global implications (updated 3 days ago).\n",
      "- **AI News** provides insights into industry trends, research advancements, product launches, and emerging technologies (curated from top sources).\n",
      "- Recent updates highlight active coverage of AI research breakthroughs and industry developments, though some search results mention future dates (e.g., June 25, 2025), which may be placeholders or system-generated timestamps.\n",
      "\n",
      "This summary reflects the most current AI-related news trends as reported by major outlets and specialized platforms. Let me know if you'd like deeper analysis on a specific topic!\n"
     ]
    }
   ],
   "source": [
    "res_1[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e1d637",
   "metadata": {},
   "source": [
    "## Advanced Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "996950d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@wrap_model_call\n",
    "def intelligent_model_selection (request: ModelRequest, handler) -> ModelResponse : \n",
    "    \"\"\"intelligent model selection based on multiple factors.\"\"\"\n",
    "    messages = request.state[\"messages\"]\n",
    "    message_count = len(messages)\n",
    "\n",
    "    total_length = sum(\n",
    "        len(str(msg.content))\n",
    "        for msg in messages\n",
    "        if hasattr(msg,\"content\") and msg.content\n",
    "    )\n",
    "\n",
    "\n",
    "    complex_keywords = [\"analysis\" , \"research\" , \"detailed\" , \"comperehensive\" , \"complex\" ,\"strategy\"]\n",
    "\n",
    "    has_complex_content = any(\n",
    "        keyword in str(msg.content).lower()\n",
    "        for msg in messages\n",
    "        for keyword in complex_keywords\n",
    "        if hasattr(msg,\"content\") and msg.content\n",
    "    )\n",
    "\n",
    "    if total_length > 3000 or has_complex_content or message_count > 8 : \n",
    "        print(message_count , total_length , has_complex_content)\n",
    "        request.model = ChatOllama(model=\"qwen3:4b\" , temperature=0.0 , num_predict=2500)\n",
    "        return handler(request)\n",
    "    else : \n",
    "        print(message_count , total_length , has_complex_content)\n",
    "        request.model = ChatOllama(model=\"qwen3:4b\" , temperature=0.1 , num_predict=1000)\n",
    "        return handler(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2dd307b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2 = create_agent(\n",
    "    model=llm1,\n",
    "    tools=[web_search],\n",
    "    middleware=[intelligent_model_selection]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e6bc896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 27 False\n",
      "3 1289 False\n"
     ]
    }
   ],
   "source": [
    "res_2 = agent2.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Search for Machine learning\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "49e48d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Machine learning (ML) is a branch of artificial intelligence focused on developing statistical algorithms that enable computers to learn from data without explicit programming. It allows systems to improve at tasks through experience, such as pattern recognition and decision-making. Key applications span healthcare, finance, and gaming, driving innovation across industries. Beginners can explore foundational skills through free resources like MIT Open Learning and Coursera courses, which provide practical insights into building and applying machine learning models.\n"
     ]
    }
   ],
   "source": [
    "res_2[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e9b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_agents_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
